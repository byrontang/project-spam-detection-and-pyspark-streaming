{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection\n",
    "\n",
    "## Outline:\n",
    "- Data Preprocessing\n",
    "- Modeling\n",
    "    - Naive Bayes\n",
    "    - Naive Bayes + ngram\n",
    "    - Logistic Regression\n",
    "    - Random Forest\n",
    "- Best Model\n",
    "    - Naive Bayes Classifier\n",
    "        - Assumptions\n",
    "    - References for Model Introduction and Algorithms\n",
    "    - More Model Introductions\n",
    "- Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, StringIndexer, NGram\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|spam|             message|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.read.option(\"delimiter\",\n",
    "                        \"\\t\").csv('..\\project-spam-detection-and-pyspark-streaming\\data\\SMSSpamCollection').toDF('spam', 'message')\n",
    "raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to tran and test sets\n",
    "trainingData, testData = raw.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word\n",
    "tokenizer = Tokenizer().setInputCol('message').setOutputCol('words')\n",
    "\n",
    "# Custom stopwords\n",
    "stopwords = StopWordsRemover().getStopWords() + ['-']\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol('words').setOutputCol('filtered')\n",
    "\n",
    "# Set 2-gram\n",
    "bigram = NGram().setN(2).setInputCol('filtered').setOutputCol('bigrams')\n",
    "\n",
    "# Generate features\n",
    "cvmodel = CountVectorizer().setInputCol('filtered').setOutputCol('features')\n",
    "cvmodel_ngram = CountVectorizer().setInputCol('bigrams').setOutputCol('features')\n",
    "\n",
    "# Convert to binary label\n",
    "indexer = StringIndexer().setInputCol('spam').setOutputCol('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|spam|             message|               words|            filtered|             bigrams|            features|label|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "| ham|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|[go jurong, juron...|(13459,[8,12,33,6...|  0.0|\n",
      "| ham|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|[ok lar..., lar.....|(13459,[0,26,307,...|  0.0|\n",
      "|spam|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|[free entry, entr...|(13459,[2,14,20,3...|  1.0|\n",
      "| ham|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|[u dun, dun say, ...|(13459,[0,71,83,1...|  0.0|\n",
      "| ham|Nah I don't think...|[nah, i, don't, t...|[nah, don't, thin...|[nah don't, don't...|(13459,[36,39,141...|  0.0|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_proprocess = Pipeline(stages = [tokenizer, remover, bigram, cvmodel, indexer])\n",
    "preprocessed = pipeline_proprocess.fit(raw)\n",
    "preprocessed.transform(raw).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Three models, Naive Bayes, Logistic Regression, and Random Forest, are used for modeling. For Naive Bayes, pipelines with and without ngram are used. For the other two models, only piple without ngram is used.\n",
    "\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|             message|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "| &lt;DECIMAL&gt; ...|  0.0|[-96.541405187808...|[0.99999999907516...|       0.0|\n",
      "| gonna let me kno...|  0.0|[-91.510438513462...|[0.99999999999997...|       0.0|\n",
      "|\"Keep ur problems...|  0.0|[-212.69897555180...|[0.99999987280161...|       0.0|\n",
      "|\"Speak only when ...|  0.0|[-29.501650783090...|[0.99999474020436...|       0.0|\n",
      "|\"The world suffer...|  0.0|[-67.080948350198...|[0.99999475556872...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.953538905240701\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(smoothing=1)\n",
    "pipeline = Pipeline(stages = [tokenizer, remover, cvmodel, indexer, nb])\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.select('message', 'label', 'rawPrediction', 'probability', 'prediction').show(5)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol('label').setRawPredictionCol('prediction').setMetricName('areaUnderROC')\n",
    "AUC = evaluator.evaluate(predictions)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes could generate fairly good prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes + ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8886194680942128\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(smoothing=1)\n",
    "pipeline = Pipeline(stages = [tokenizer, remover, bigram, cvmodel_ngram, indexer, nb])\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "#predictions.select('message', 'label', 'rawPrediction', 'probability', 'prediction').show(5)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol('label').setRawPredictionCol('prediction').setMetricName('areaUnderROC')\n",
    "AUC = evaluator.evaluate(predictions)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, including ngram does not improve prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "pipeline = Pipeline(stages = [tokenizer, remover, cvmodel, indexer, log_reg])\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol('label').setRawPredictionCol('prediction').setMetricName('areaUnderROC')\n",
    "AUC = evaluator.evaluate(predictions)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of Logistic Regression shows no better performance than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5093896713615024\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier().setLabelCol('label').setFeaturesCol('features').setNumTrees(10)\n",
    "pipeline = Pipeline(stages = [tokenizer, remover, cvmodel, indexer, rf])\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol('label').setRawPredictionCol('prediction').setMetricName(\"areaUnderROC\")\n",
    "AUC = evaluator.evaluate(predictions)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither does Random Forest generate much better result than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "Naive Bayes without ngram in pipeline is clearly the best model for spam detection. The natural of this model actually fit very well to the problem, where the data fram contains sparse data. On the other hand, logistic regression and random forest do not have any advantages when it comes to this type of question/dataset. A brief introduction on Naive Bayes model is discussed below.\n",
    "\n",
    "### Naive Bayes Classifier\n",
    "\n",
    "The Naive Bayes classifier uses a simplifying assumption that, that probability of $a_1$, $a_24$, to $a_d$ and given label $y$ is the product of the probability of each feature ($a_1$ to $a_d$) given $y$.\n",
    "$$ p(a_1, a_2, ..., a_d|y) = \\prod_{j}p(a_j|y)$$\n",
    "\n",
    "#### Algorithm\n",
    "**Learning:** Based on the frequency counts in the dataset:\n",
    "1. Estimate all $p(y), \\forall_y \\in \\mathbb{Y}$\n",
    "2. Estimate all $p(a_i|y) \\forall_y \\in \\mathbb{Y}, \\forall a_i$\n",
    "**Classification:** For a new sample, use:\n",
    "$$y_{new} = \\operatorname*{arg\\,max}_{y \\in Y} p(y) \\prod_{j}p(a_j|y)$$\n",
    "\n",
    "***Note: No model per se or hyperplane, just count the frequencies of various data combinations within the training examples.***\n",
    "\n",
    "### References for Model Introduction and Algorithms\n",
    "- Post Graduate Diploma of Applied Machine Learning and Artificial Intelligence - Columnbia Engineering Executive Education\n",
    "\n",
    "### More Model Introductions\n",
    "For more detailed discussion on Bayes Classifier, Logistic Regression, and Random Forest, please refer the the notebook **models-and-algothrms** in [project-parkinsons-disease-classification on my GitHub](https://github.com/byrontang/project-parkinsons-disease-classification).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "With the best model identified, the next step would be to build an application that predicts the spam message with the model on the steaming data. The application will connect to flume to retrieve streaming data and make prediction in near real time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
